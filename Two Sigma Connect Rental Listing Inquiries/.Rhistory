x = c(18,19,56,128,178,66,23.16)
x = c(18,19,56,128,178,66,23,16)
chisq.test(x)
year <- c(2000 ,   2001  ,  2002  ,  2003 ,   2004)
rate <- c(9.34 ,   8.50  ,  7.62  ,  6.93  ,  6.60)
plot(year,rate)
plot(log(year),lg(rate))
plot(log(year),log(rate))
year.log <-log(year)
year.rate <- log(rate)
plot(year.log,year.rate)
rate.log <- log(rate)
year.log <-log(year)
rate.log
year.log
model <- lm(rate~year)
model.log <- lm(rate.log,year.log)
model.log <- lm(rate.log,year.log)
lm(rate.log,year.log)
model.log <- lm(rate.log ~year.log)
mean(model$residuals)
mean(model.log$residuals)
height <- c(176, 154, 138, 196, 132, 176, 181, 169, 150, 175)
bodymass <- c(82, 49, 53, 112, 47, 69, 77, 71, 62, 78)
model1 <- lm(height~bodymass)
mean(model1$residuals)
plot(height,model1$residuals)
pt(1.59,2)
1-.87
pt(1.5869,2)
pt(3.04,92)
1- pt(3.04,92)
1- pt(3.04,2)
1- pt(4.2,45)
1- pt(-0.42,26)
171.75081/40.86339
pt(4.2,45)
1 - pt(4.2,45)
1 - pt(1.5869,34)
1 - pt(3.7060,34)
qt(.025,34)
pf(48.38,2)
pf(48.38,2,34)
pf(48.38,34,2)
1-pf(48.38,34,2)
1-pf(45.49,62,2)
pf(45.49,62,2)
1-pf(45.49,2,62)
?of
?pf
1-pf(45.49,2,62)
1-pf(48.38,2,34)
qnorm
qnorm(.95,3.5,1.707825128)
qnorm(p=.975)
readingSkills
install.packages("party")
library(party)
install.packages("installr")
require(installr)
updateR()
install.packages("installr")
require("installR","C:/Program Files/R/R-3.3.1/library")
install.packages("installR")
install.packages("installr")
library(installr)
updateR()
setwd(readClipboard())
stock.prices.data <- read.csv("data/stock_prices.csv")
dji.data <- read.csv("data/DJI.csv")
head(stock.prices.data)
library(lubridate)
stock.prices.data <- transform(stock.prices.data, Date = ymd(Date))
library(lubridate)
head(stock.prices.data)
library(reshape2)
?cast
stock.prices.matrix <- dcast(stock.prices.data, formula = Date ~ Stock)
stock.prices.matrix <- dcast(stock.prices.data, formula = Date ~ Stock, value.var = Close)
stock.prices.matrix <- dcast(stock.prices.data, formula = Date ~ Stock, value.var = "Close")
head(stock.prices.matrix)
ggplot(stock.prices.data,aes(x = Date,y = Close, color = Stock))+
geom_line()
library(ggplot2)
#-------Visualiza stocks over time
ggplot(stock.prices.data,aes(x = Date,y = Close, color = Stock))+
geom_line()
ggplot(stock.prices.matrix,aes(x = Date,y = ADC)+
geom_line()
#-------Visualiza stocks over time
ggplot(stock.prices.matrix,aes(x = Date,y = ADC))+
geom_line()
apply(stock.prices.matrix,2,sum(is.na(x)))
apply(stock.prices.matrix,2,function(x){sum(is.na(x))})
stock.prices.matrix[is.na(ADC),]
stock.prices.matrix[is.na(stock.prices.matrix$ADC),]
prices <- stock.prices.matrix %>% filter(Date != "2002-02-01")
library(dplyr)
prices <- stock.prices.matrix %>% filter(Date != "2002-02-01")
rm(stock.prices.matrix)
cor.prices <- cor(prices[,2:ncol(prices)],)
plot(cor.prices)
cor.prices <- cor(prices[,2:ncol(prices)])
plot(cor.prices)
require(corrplot)
install.packages("corrplot")
require(corrplot)
corrplot(cor.prices)
corrplot(cor.prices,method = number)
corrplot(cor.prices,method = "number")
heaD(cor.prices)
head(cor.prices)
cor.matrix <- as.numeric(cor.prices)
head(cor.matrix)
str(cor.matrix)
ggplot(data.frame(Correlations = cor.matrix),aes(x=Correlations,fill = 1)) +
geom_density()+
opts(legend.position = "none")
ggplot(data.frame(Correlations = cor.matrix),aes(x=Correlations,fill = 1)) +
geom_density()+
options(legend.position = "none")
length(cor.matrix)
dim(cor.prices)
str(cor.prices)
pca <- princomp(prices[,2:ncol(prices)])
corrplot(cor.prices,method = "number")
prices[1,"DDR"]
prices[,"DDR"]
apply(stock.prices.matrix,2,function(x){sum(is.na(x))})
stock.prices.matrix <- dcast(stock.prices.data, formula = Date ~ Stock, value.var = "Close")
apply(stock.prices.matrix,2,function(x){sum(is.na(x))})
stock.prices.matrix[is.na(stock.prices.matrix$ADC),]
apply(stock.prices.matrix,2,function(x){sum(is.na(x))})
prices <- stock.prices.matrix %>% filter(Date != "2002-02-01")
rm(stock.prices.matrix)
apply(stock.prices.matrix,2,function(x){sum(is.na(x))})
apply(prices,2,function(x){sum(is.na(x))})
prices[is.na(prices$DDR),]
stock.prices.matrix <- dcast(stock.prices.data, formula = Date ~ Stock, value.var = "Close")
stock.prices.matrix[is.na(stock.prices.matrix$ADC) || is.na(stock.prices.matrix$DDR),]
apply(stock.prices.matrix,2,function(x){sum(is.na(x))})
stock.prices.matrix[is.na(stock.prices.matrix$ADC),]
stock.prices.matrix[is.na(stock.prices.matrix$ADC) | is.na(stock.prices.matrix$DDR),]
prices <- stock.prices.matrix %>% filter(Date != "2002-02-01" & Date != "2005-06-22")
stock.prices.matrix[is.na(stock.prices.matrix$ADC) | is.na(stock.prices.matrix$DDR),]
apply(prices,2,function(x){sum(is.na(x))})
rm(stock.prices.matrix)
cor.prices <- cor(prices[,2:ncol(prices)])
corrplot(cor.prices,method = "number")
pca <- princomp(prices[,2:ncol(prices)])
head(pca)
pca
pca.numberic <- as.numeric(pca)
ggplot(data.frame(pca = pca.numberic),aes(x=pca,fill = 1))+
geom_density()
ggplot(data.frame(pca = pca.numeric),aes(x=pca,fill = 1))+
geom_density()
pca.numeric <- as.numeric(pca)
str(pca)
str(prices)
str(pca$loadings)
pca$loadings
pca$loadings[,1]
pca$loadings[1,1]
pca$loadings[,1]
str(pca$loadings)
pca.loadings <- as.numeric(pca$loadings[,1])
pca.numeric <- as.numeric(pca.loadings)
ggplot(data.frame(pca = pca.numeric),aes(x=pca,fill = 1))+
geom_density()
predict(pca)
market.index <- predict(pca)[,1]
dji.data <- transform(dji.data,Date = ymd(Date))
head(dji.data)
dji.data %>% arrange(Date)
ggplot()+
geom_boxplot(dji.data$Date)
geom_boxplot(dji.data$Date,aes(y=Date))
geom_boxplot(dji.data,aes(y=Date))
ggplot()+
geom_boxplot(dji.data,aes(y=Date))
ggplot()+
geom_density(dji.data,aes(y=Date))
ggplot(dji.data)+
geom_density(aes(x=Date))
gglot(rbind(data.frame(Date = prices$Date,Group = "Group1"),data.frame(dji.data$Date,"Group2"))
,aes(x= Date, fill=Group))+
geom_density()
ggplot(rbind(data.frame(Date = prices$Date,Group = "Group1"),data.frame(dji.data$Date,"Group2"))
,aes(x= Date, fill=Group))+
geom_density()
rbind(data.frame(Date = prices$Date,Group = "Group1"),data.frame(dji.data$Date,"Group2"))
rbind(data.frame(Date = prices$Date,Group = "Group1"),data.frame(Date = dji.data$Date,Group = "Group2"))
ggplot(rbind(data.frame(Date = prices$Date,Group = "Group1"),data.frame(Date = dji.data$Date,Group = "Group2"))
,aes(x= Date, fill=Group))+
geom_density()
min(prices$Date)
dji.data <- dji.data %>% filter(Date >="2002-01-02")
dji.data <- dji.data %>% filter(Date >="2002-01-02") %>% filter(Date != "2002-02-01" & Date != "2005-06-22")
head(dji.data)
with(dji.data,rev(Dates))
with(dji.data,rev(Date))
head(dji.data)
with(dji.data,rev(Close))
?rev
rev(c(1,2,3,4,5))
index.comparison <- data.frame(
Dates = with(dji.data,rev(Date))
,MarketIndex = market.index
,DJI = with(dji.data,rev(Close))
)
ggplot(index.comparison,aes(x = MarketIndex,y=DJI))+
geom_point()+
geom_smooth(method = "lm")
index.comparison <- data.frame(
Dates = with(dji.data,rev(Date))
,MarketIndex = market.index * -1
,DJI = with(dji.data,rev(Close))
)
ggplot(index.comparison,aes(x = MarketIndex,y=DJI))+
geom_point()+
geom_smooth(method = "lm")
?melt
melt(index.comparison,id.vars = "Date")
melt(index.comparison,id.vars = "Dates")
alt.comparison <- melt(index.comparison,id.vars = "Date")
alt.comparison <- melt(index.comparison,id.vars = "Date")
alt.comparison <- melt(index.comparison,id.vars = "Dates")
head(alt.comparison)
colnames(alt.comparison) <- c("Dates","Index","Value")
colnames(alt.comparison) <- c("Dates","Index","Price")
ggplot(alt.comparison,aes(x = Dates,y = Price,group = Index,color = Index))+
geom_point()+
geom_line()
index.comparison <- data.frame(
Dates = with(dji.data,rev(Date))
,MarketIndex = scale(market.index) * -1
,DJI = with(dji.data,scale(rev(Close)))
)
ggplot(index.comparison,aes(x = MarketIndex,y=DJI))+
geom_point()+
geom_smooth(method = "lm")
alt.comparison <- melt(index.comparison,id.vars = "Dates")
colnames(alt.comparison) <- c("Dates","Index","Price")
ggplot(alt.comparison,aes(x = Dates,y = Price,group = Index,color = Index))+
geom_point()+
geom_line()
predict(pca)
predict(pca)[,1]
predict(pca)[,1:2]
colnamesprices[1,2]
prices[1,2]
prices[,2]
rm(list = ls())
packages <- c("jsonlite", "dplyr", "purrr")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
library(data.table)
library(xgboost)
library(caret)
library(stringr)
library(quanteda)
library(lubridate)
library(stringr)
library(Hmisc)
library(Matrix)
catNWayAvgCV <- function(data, varList, y, pred0, filter, k, f, g=1, lambda=NULL, r_k, cv=NULL){
# It is probably best to sort your dataset first by filter and then by ID (or index)
n <- length(varList)
varNames <- paste0("v",seq(n))
ind <- unlist(cv, use.names=FALSE)
oof <- NULL
if (length(cv) > 0){
for (i in 1:length(cv)){
sub1 <- data.table(v1=data[,varList,with=FALSE], y=data[,y,with=FALSE], pred0=data[,pred0,with=FALSE], filt=filter)
sub1 <- sub1[sub1$filt==TRUE,]
sub1[,filt:=NULL]
colnames(sub1) <- c(varNames,"y","pred0")
sub2 <- sub1[cv[[i]],]
sub1 <- sub1[-cv[[i]],]
sum1 <- sub1[,list(sumy=sum(y), avgY=mean(y), cnt=length(y)), by=varNames]
tmp1 <- merge(sub2, sum1, by = varNames, all.x=TRUE, sort=FALSE)
set(tmp1, i=which(is.na(tmp1[,cnt])), j="cnt", value=0)
set(tmp1, i=which(is.na(tmp1[,sumy])), j="sumy", value=0)
if(!is.null(lambda)) tmp1[beta:=lambda] else tmp1[,beta:= 1/(g+exp((tmp1[,cnt] - k)/f))]
tmp1[,adj_avg:=((1-beta)*avgY+beta*pred0)]
set(tmp1, i=which(is.na(tmp1[["avgY"]])), j="avgY", value=tmp1[is.na(tmp1[["avgY"]]), pred0])
set(tmp1, i=which(is.na(tmp1[["adj_avg"]])), j="adj_avg", value=tmp1[is.na(tmp1[["adj_avg"]]), pred0])
set(tmp1, i=NULL, j="adj_avg", value=tmp1$adj_avg*(1+(runif(nrow(sub2))-0.5)*r_k))
oof <- c(oof, tmp1$adj_avg)
}
}
oofInd <- data.frame(ind, oof)
oofInd <- oofInd[order(oofInd$ind),]
sub1 <- data.table(v1=data[,varList,with=FALSE], y=data[,y,with=FALSE], pred0=data[,pred0,with=FALSE], filt=filter)
colnames(sub1) <- c(varNames,"y","pred0","filt")
sub2 <- sub1[sub1$filt==F,]
sub1 <- sub1[sub1$filt==T,]
sum1 <- sub1[,list(sumy=sum(y), avgY=mean(y), cnt=length(y)), by=varNames]
tmp1 <- merge(sub2, sum1, by = varNames, all.x=TRUE, sort=FALSE)
tmp1$cnt[is.na(tmp1$cnt)] <- 0
tmp1$sumy[is.na(tmp1$sumy)] <- 0
if(!is.null(lambda)) tmp1$beta <- lambda else tmp1$beta <- 1/(g+exp((tmp1$cnt - k)/f))
tmp1$adj_avg <- (1-tmp1$beta)*tmp1$avgY + tmp1$beta*tmp1$pred0
tmp1$avgY[is.na(tmp1$avgY)] <- tmp1$pred0[is.na(tmp1$avgY)]
tmp1$adj_avg[is.na(tmp1$adj_avg)] <- tmp1$pred0[is.na(tmp1$adj_avg)]
# Combine train and test into one vector
return(c(oofInd$oof, tmp1$adj_avg))
}
# Load training set
print("loading training set")
t1 <- fromJSON("train.json")
t1_feats <- data.table(listing_id=rep(unlist(t1$listing_id), lapply(t1$features, length)), features=unlist(t1$features))
t1_photos <- data.table(listing_id=rep(unlist(t1$listing_id), lapply(t1$photos, length)), features=unlist(t1$photos))
vars <- setdiff(names(t1), c("photos", "features"))
t1<- map_at(t1, vars, unlist) %>% as.data.table(.)
t1[,":="(filter=0)]
# create 5 fold CV
set.seed(321)
cvFoldsList <- createFolds(t1$interest_level, k=5, list=TRUE, returnTrain=FALSE)
# Convert classes to integers for xgboost
class <- data.table(interest_level=c("low", "medium", "high"), class=c(0,1,2))
t1 <- merge(t1, class, by="interest_level", all.x=TRUE, sort=F)
# Load test set
print("loading test set")
s1 <- fromJSON("test.json")
s1_feats <- data.table(listing_id=rep(unlist(s1$listing_id), lapply(s1$features, length)), features=unlist(s1$features))
s1_photos <- data.table(listing_id=rep(unlist(s1$listing_id), lapply(s1$photos, length)), features=unlist(s1$photos))
vars <- setdiff(names(s1), c("photos", "features"))
s1<- map_at(s1, vars, unlist) %>% as.data.table(.)
s1[,":="(interest_level="-1",
class=-1,
filter=2)]
setwd("F:/Sid/Learnings/Data Scientist/Machine Learning With Kaggle/Two Sigma Connect Rental Listing Inquiries")
packages <- c("jsonlite", "dplyr", "purrr")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
library(data.table)
library(xgboost)
library(caret)
library(stringr)
library(quanteda)
library(lubridate)
library(stringr)
library(Hmisc)
library(Matrix)
catNWayAvgCV <- function(data, varList, y, pred0, filter, k, f, g=1, lambda=NULL, r_k, cv=NULL){
# It is probably best to sort your dataset first by filter and then by ID (or index)
n <- length(varList)
varNames <- paste0("v",seq(n))
ind <- unlist(cv, use.names=FALSE)
oof <- NULL
if (length(cv) > 0){
for (i in 1:length(cv)){
sub1 <- data.table(v1=data[,varList,with=FALSE], y=data[,y,with=FALSE], pred0=data[,pred0,with=FALSE], filt=filter)
sub1 <- sub1[sub1$filt==TRUE,]
sub1[,filt:=NULL]
colnames(sub1) <- c(varNames,"y","pred0")
sub2 <- sub1[cv[[i]],]
sub1 <- sub1[-cv[[i]],]
sum1 <- sub1[,list(sumy=sum(y), avgY=mean(y), cnt=length(y)), by=varNames]
tmp1 <- merge(sub2, sum1, by = varNames, all.x=TRUE, sort=FALSE)
set(tmp1, i=which(is.na(tmp1[,cnt])), j="cnt", value=0)
set(tmp1, i=which(is.na(tmp1[,sumy])), j="sumy", value=0)
if(!is.null(lambda)) tmp1[beta:=lambda] else tmp1[,beta:= 1/(g+exp((tmp1[,cnt] - k)/f))]
tmp1[,adj_avg:=((1-beta)*avgY+beta*pred0)]
set(tmp1, i=which(is.na(tmp1[["avgY"]])), j="avgY", value=tmp1[is.na(tmp1[["avgY"]]), pred0])
set(tmp1, i=which(is.na(tmp1[["adj_avg"]])), j="adj_avg", value=tmp1[is.na(tmp1[["adj_avg"]]), pred0])
set(tmp1, i=NULL, j="adj_avg", value=tmp1$adj_avg*(1+(runif(nrow(sub2))-0.5)*r_k))
oof <- c(oof, tmp1$adj_avg)
}
}
oofInd <- data.frame(ind, oof)
oofInd <- oofInd[order(oofInd$ind),]
sub1 <- data.table(v1=data[,varList,with=FALSE], y=data[,y,with=FALSE], pred0=data[,pred0,with=FALSE], filt=filter)
colnames(sub1) <- c(varNames,"y","pred0","filt")
sub2 <- sub1[sub1$filt==F,]
sub1 <- sub1[sub1$filt==T,]
sum1 <- sub1[,list(sumy=sum(y), avgY=mean(y), cnt=length(y)), by=varNames]
tmp1 <- merge(sub2, sum1, by = varNames, all.x=TRUE, sort=FALSE)
tmp1$cnt[is.na(tmp1$cnt)] <- 0
tmp1$sumy[is.na(tmp1$sumy)] <- 0
if(!is.null(lambda)) tmp1$beta <- lambda else tmp1$beta <- 1/(g+exp((tmp1$cnt - k)/f))
tmp1$adj_avg <- (1-tmp1$beta)*tmp1$avgY + tmp1$beta*tmp1$pred0
tmp1$avgY[is.na(tmp1$avgY)] <- tmp1$pred0[is.na(tmp1$avgY)]
tmp1$adj_avg[is.na(tmp1$adj_avg)] <- tmp1$pred0[is.na(tmp1$adj_avg)]
# Combine train and test into one vector
return(c(oofInd$oof, tmp1$adj_avg))
}
# Load training set
print("loading training set")
t1 <- fromJSON("train.json")
t1_feats <- data.table(listing_id=rep(unlist(t1$listing_id), lapply(t1$features, length)), features=unlist(t1$features))
t1_photos <- data.table(listing_id=rep(unlist(t1$listing_id), lapply(t1$photos, length)), features=unlist(t1$photos))
vars <- setdiff(names(t1), c("photos", "features"))
t1<- map_at(t1, vars, unlist) %>% as.data.table(.)
t1[,":="(filter=0)]
# create 5 fold CV
set.seed(321)
cvFoldsList <- createFolds(t1$interest_level, k=5, list=TRUE, returnTrain=FALSE)
# Convert classes to integers for xgboost
class <- data.table(interest_level=c("low", "medium", "high"), class=c(0,1,2))
t1 <- merge(t1, class, by="interest_level", all.x=TRUE, sort=F)
# Load test set
print("loading test set")
s1 <- fromJSON("test.json")
s1_feats <- data.table(listing_id=rep(unlist(s1$listing_id), lapply(s1$features, length)), features=unlist(s1$features))
s1_photos <- data.table(listing_id=rep(unlist(s1$listing_id), lapply(s1$photos, length)), features=unlist(s1$photos))
vars <- setdiff(names(s1), c("photos", "features"))
s1<- map_at(s1, vars, unlist) %>% as.data.table(.)
s1[,":="(interest_level="-1",
class=-1,
filter=2)]
rep(c(1,2),c(2,1))
View(head(t1))
ts1 <- rbind(t1, s1)
rm(t1, s1);gc()
ts1_feats <- rbind(t1_feats, s1_feats)
rm(t1_feats, s1_feats);gc()
ts1_photos <- rbind(t1_photos, s1_photos)
rm(t1_photos, s1_photos);gc()
ts1[,":="(created=as.POSIXct(created)
,dummy="A"
,low=as.integer(interest_level=="low")
,medium=as.integer(interest_level=="medium")
,high=as.integer(interest_level=="high")
,display_address=trimws(tolower(display_address))
,street_address=trimws(tolower(street_address)))]
ts1[, ":="(pred0_low=sum(interest_level=="low")/sum(filter==0),
pred0_medium=sum(interest_level=="medium")/sum(filter==0),
pred0_high=sum(interest_level=="high")/sum(filter==0))]
View(head(ts1))
ts1 %>% filter(class == -1) %>% head()
ts1 %>% filter(class == -1) %>% head() %>% View()
ts1 %>% filter(class == 0) %>% head() %>% View()
View(head(ts1_feats))
ts1_feats[,features:=gsub(" ", "_", paste0("feature_",trimws(char_tolower(features))))]
feats_summ <- ts1_feats[,.N, by=features]
ts1_feats_cast <- dcast.data.table(ts1_feats[!features %in% feats_summ[N<10, features]], listing_id ~ features, fun.aggregate = function(x) as.integer(length(x) > 0), value.var = "features")
ts1_feats_cast %>% View(head())
ts1_feats_cast %>% head() %>% View()
ts1 <- merge(ts1, ts1_feats_cast, by="listing_id", all.x=TRUE, sort=FALSE)
rm(ts1_feats_cast);gc()
ts1_photos_summ <- ts1_photos[,.(photo_count=.N), by=listing_id]
ts1 <- merge(ts1, ts1_photos_summ, by="listing_id", all.x=TRUE, sort=FALSE)
rm(ts1_photos, ts1_photos_summ);gc()
View(head(ts1))
build_count <- ts1[,.(.N), by=building_id]
manag_count <- ts1[,.(.N), by=manager_id]
add_count <- ts1[,.(.N), by=display_address]
?set
set(ts1, i=which(ts1[["building_id"]] %in% build_count[N==1, building_id]), j="building_id", value="-1")
set(ts1, i=which(ts1[["manager_id"]] %in% manag_count[N==1, manager_id]), j="manager_id", value="-1")
set(ts1, i=which(ts1[["display_address"]] %in% add_count[N==1, display_address]), j="display_address", value="-1")
print("target encoding")
highCard <- c(
"building_id",
"manager_id"
)
ts1 %>% filter(manager_id == -1) %>% head() %>% View()
debug(catNWayAvgCV)
for (col in 1:length(highCard)){
# ts1[,paste0(highCard[col],"_mean_low"):=catNWayAvgCV(ts1, varList=c("dummy",highCard[col]), y="low", pred0="pred0_low", filter=ts1[["filter"]]==0, k=10, f=2, r_k=0.02, cv=cvFoldsList)]
ts1[,paste0(highCard[col],"_mean_med"):=catNWayAvgCV(ts1, varList=c("dummy",highCard[col]), y="medium", pred0="pred0_medium", filter=ts1$filter==0, k=5, f=1, r_k=0.01, cv=cvFoldsList)]
ts1[,paste0(highCard[col],"_mean_high"):=catNWayAvgCV(ts1, varList=c("dummy",highCard[col]), y="high", pred0="pred0_high", filter=ts1$filter==0, k=5, f=1, r_k=0.01, cv=cvFoldsList)]
}
y
pred0
filter
k
k
r_k
length(varList)
cv
str(cv)
View(head(sub1))
View(head(tmp1))
View(head(tmp1))
g
tmp1[["avgY"]]
View(head(oofInd))
View(head(ts1))
ts1$building_id_mean_med
# Create some date and other features
print("creating some more features")
ts1[,":="(building_id=as.integer(as.factor(building_id))
,display_address=as.integer(as.factor(display_address))
,manager_id=as.integer(as.factor(manager_id))
,street_address=as.integer(as.factor(street_address))
,desc_wordcount=str_count(description)
,pricePerBed=ifelse(!is.finite(price/bedrooms),-1, price/bedrooms)
,pricePerBath=ifelse(!is.finite(price/bathrooms),-1, price/bathrooms)
,pricePerRoom=ifelse(!is.finite(price/(bedrooms+bathrooms)),-1, price/(bedrooms+bathrooms))
,bedPerBath=ifelse(!is.finite(bedrooms/bathrooms), -1, price/bathrooms)
,bedBathDiff=bedrooms-bathrooms
,bedBathSum=bedrooms+bathrooms
,bedsPerc=ifelse(!is.finite(bedrooms/(bedrooms+bathrooms)), -1, bedrooms/(bedrooms+bathrooms)))
]
# fill in missing values with -1
print("fill in missing values")
for (col in 1:ncol(ts1)){
set(ts1, i=which(is.na(ts1[[col]])), j=col, value=-1)
}
print("get variable names")
varnames <- setdiff(colnames(ts1), c("photos","pred0_high", "pred0_low","pred0_medium","description", "features","interest_level","dummy","filter", "created", "class", "low","medium","high","street"))
# Convert dataset to sparse format
print("converting data to sparse format")
t1_sparse <- Matrix(as.matrix(ts1[filter==0, varnames, with=FALSE]), sparse=TRUE)
s1_sparse <- Matrix(as.matrix(ts1[filter==2, varnames, with=FALSE]), sparse=TRUE)
listing_id_test <- ts1[filter %in% c(2), listing_id]
class
setdiff(colnames(ts1), c("photos","pred0_high", "pred0_low","pred0_medium","description", "features","interest_level","dummy","filter", "created", "class", "low","medium","high","street"))
?aggregate
unlist(cv, use.names=FALSE)
